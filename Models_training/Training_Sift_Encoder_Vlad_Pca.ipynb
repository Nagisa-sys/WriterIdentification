{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Sift_Encoder_Vlad_Pca.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyO0ZhVIMFegPmS+jzLU/f5W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dSBXRqGMmLVu","colab_type":"text"},"source":["#Modules Importation and preparation"]},{"cell_type":"code","metadata":{"id":"jElVyQikuw_A","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"buSqBXaSuzzQ","colab_type":"code","colab":{}},"source":["WORK_DIR = \"/content/drive/My Drive/Colab Notebooks/Writer_identification\"\n","!pip uninstall -y opencv-python\n","!pip install -U opencv-contrib-python\n","% cd \"/content/drive/My Drive/Colab Notebooks/Writer_identification\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdLCQ9Bt2dQr","colab_type":"code","colab":{}},"source":["import Clusterer, Global_feature_exractors, Local_features_extractor, Norms, Image, PCA_reduction, Distances\n","from Dataset_loader import train_test_IAM, train_test_ICDAR2013, train_test_TrigraphSlant\n","from Accuracy import accuracy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle, json, os\n","import Norms, Local_features_extractor, Image, Autoencoder, Clusterer\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEJQU9UC2t2y","colab_type":"code","colab":{}},"source":["training_session = \"training_16Sep\"\n","\n","with open(\"./config_train.json\") as config_file:\n","  configuration = json.load(config_file)[\"Sift_Encoder_Vlad_Pca\"][training_session]\n","\n","CLUSTERS_CENTERS_PATH = training_session+\"/centers_clusters_NN_VLAD.npy\"\n","PCA_MODEL_PATH = training_session+\"/pca_model_NN_VLAD.pkl\"\n","IMAGES_PATCHS_PATH = training_session+\"/pickle_patchs_NN_VLAD.dat\"\n","ENCODER_MODEL = training_session+\"/Encoder_model.h5\"\n","\n","if not os.path.exists(training_session):\n","  os.mkdir(training_session)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkUoXwRyCVyP","colab_type":"code","colab":{}},"source":["train, test = train_test_IAM(\"./dataset/IAM\", size_train=configuration[\"train_size\"], size_test=configuration[\"test_size\"])\n","_, _, images_train_set = map(list, zip(*train))\n","writers_test_set, images_names_test_set, images_test_set = map(list, zip(*test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3dPV7mpq0OC","colab_type":"text"},"source":["#Train Model"]},{"cell_type":"code","metadata":{"id":"BPKe6E3NuaFB","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Reshape\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLkiVQa975zH","colab_type":"code","colab":{}},"source":["class Autoencoder_train:\n","\tdef __init__(self, configuration, data_path, model_path):\n","\t\tself.configuration = configuration\n","\t\tself.shape_images = (configuration[\"shape_images\"]*2,configuration[\"shape_images\"]*2)\n","\t\tself.model_path = model_path\n","\t\tself.data_path = data_path\n","\n","\tdef train_network(self):\n","\t\ttest_ration = self.configuration[\"autoencoder_test_ration\"]\n","\t\tEPOCHS = self.configuration[\"EPOCHS\"]\n","\t\tBS = self.configuration[\"BS\"]\n","\n","\t\ttrainX, testX = self.load_data_patchs(self.data_path, test_ration)\n","\n","\t# add a channel dimension to every image in the dataset, then scale\n","\t# the pixel intensities to the range [0, 1]\n","\t\ttrainX \t= np.expand_dims(trainX, axis=-1)\n","\t\ttestX \t= np.expand_dims(testX, axis=-1)\n","\t\ttrainX \t= trainX.astype(\"float32\") / 255.0\n","\t\ttestX \t= testX.astype(\"float32\") / 255.0\n","\n","\t# construct the convolutional autoencoder\n","\t\tprint(\"[INFO] building autoencoder...\")\n","\t\t(encoder, decoder, autoencoder) = self.build(self.shape_images[0], self.shape_images[1], 1)\n","\t\tautoencoder.compile(loss=\"mse\", optimizer=Adam(lr=1e-3))\n","\n","\t# train the convolutional autoencoder\n","\t\tH = autoencoder.fit(trainX, trainX,\n","\t\t\t\t\t\t\tvalidation_data=(testX, testX),\n","\t\t\t\t\t\t\tepochs=EPOCHS,\n","\t\t\t\t\t\t\tbatch_size=BS)\n","\n","\t\tself.plot_loss_accuracy(H, EPOCHS)\n","\t\tencoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(\"encoder\").output)\n","\t\tself.save_model(encoder, self.model_path)\n","\t\tself.test_autoencoder(autoencoder, testX)\n","\t\n","\tdef test_autoencoder(self, autoencoder, testX):\n","\t\tprint(\"[INFO] making predictions...\")\n","\t\tdecoded = autoencoder.predict(testX)\n","\t\toutputs = None\n","\t\tfor i in range(0, 20):\n","\t\t\toriginal = (testX[i] * 255).astype(\"uint8\")\n","\t\t\trecon = (decoded[i] * 255).astype(\"uint8\")\n","\t\t\toutput = np.hstack([original, recon])\n","\t\t\tif outputs is None:\n","\t\t\t\toutputs = output\n","\t\t\telse:\n","\t\t\t\toutputs = np.vstack([outputs, output])\n","\t\tcv2_imshow(outputs)\n","\n","\tdef load_data_patchs(self, PIK, test_ration):\n","\t\twith open(PIK,'rb') as f:\n","\t\t\tdata = np.array(pickle.load(f))\n","\n","\t\tsize_test = int(len(data)*test_ration)\n","\t\tnp.random.shuffle(data)\n","\t\treturn data[size_test:], data[:size_test]\n","\n","\n","\tdef save_model(self, model, model_path):\n","\t\tsave_format = \"h5\"\n","\t\tprint(\"[INFO] saving encoder...\")\n","\t\tmodel.save(model_path, save_format=save_format, include_optimizer=False)\n","\n","\n","\tdef plot_loss_accuracy(self, H, EPOCHS):\n","\t\tN = np.arange(0, EPOCHS)\n","\t\tplt.style.use(\"ggplot\")\n","\t\tplt.figure()\n","\t\tplt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","\t\tplt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","\t\tplt.title(\"Training Loss and Accuracy\")\n","\t\tplt.xlabel(\"Epoch #\")\n","\t\tplt.ylabel(\"Loss/Accuracy\")\n","\t\tplt.legend(loc=\"lower left\")\n","\n","\n","\t\n","\tdef build(self, width, height, depth, filters=(32, 64)):\n","\t\tlatentDim = self.configuration[\"latentDim\"]\n","\t\tinputShape = (height, width, depth)\n","\n","\t\tinputs = Input(shape=inputShape)\n","\t\tx = inputs\n","\n","\t\tfor f in filters:\n","\t\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n","\t\t\tx = LeakyReLU(alpha=0.2)(x)\n","\t\t\tx = BatchNormalization()(x)\n","\n","\t\tvolumeSize = K.int_shape(x)\n","\t\tx = Flatten()(x)\n","\t\tlatent = Dense(latentDim)(x)\n","\t\tencoder = Model(inputs, latent, name=\"encoder\")\n","\n","\t\tprint(encoder.summary())\n","\n","\t\tlatentInputs = Input(shape=(latentDim,))\n","\t\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n","\t\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n","\n","\t\tfor f in filters[::-1]:\n","\t\t\tx = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n","\t\t\tx = LeakyReLU(alpha=0.2)(x)\n","\t\t\tx = BatchNormalization()(x)\n","\n","\t\tx = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n","\t\toutputs = Activation(\"sigmoid\")(x)\n","\t\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n","\n","\t\tautoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n","\t\treturn (encoder, decoder, autoencoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29t55ZW5zfPJ","colab_type":"code","colab":{}},"source":["def generate_patchs(PatchsPickle, images, height):\n","\tsift = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm)\n","\timages_pre = [Image.Image(image, local_feature_extractor=sift) for image in images]\n","\timages_patch = list()\n","\n","\tfor image in images_pre:\n","\t\tfor key_point in image.key_points:\n","\t\t\ty,x = int(key_point.pt[0]),int(key_point.pt[1])\n","\t\t\txm, ym = image.image.shape\n","\t\t\tif (x-height < 0) or (x+height > xm) or (y-height < 0) or (y+height > ym):\n","\t\t\t\tcontinue\n","\t\t\tcropped = image.image[x-height:x+height,y-height:y+height]\n","\t\t\timages_patch.append(cropped)\n","\n","\twith open(PatchsPickle, \"wb\") as f:\n","\t\tpickle.dump(images_patch, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QITjJYdQQSjo","colab_type":"code","colab":{}},"source":["def choose_number_clusters(images, model_path, max_no_improvement, shape_images, max_key_points, test_values=range(1, 500, 50)):\n","\tautoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n","\tautoencoder.set_model(model_path=model_path)\n","\tsift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n","\n","\timages_pre = [Image.Image(image, local_feature_extractor=sift_autoencoder) for image in images]\n","\n","\tClusterer.Clusterer.elbow_method_kmeans(images_pre, \n","\t                                        max_no_improvement=max_no_improvement,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttest_values=test_values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iX9-w3ROzigg","colab_type":"code","colab":{}},"source":["def save_new_clusters_centers(images, model_path, path_to_save, nb_clusters, max_no_improvement, shape_images, max_key_points):\n","\tautoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n","\tautoencoder.set_model(model_path=model_path)\n","\tsift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n","\n","\timages_pre = [Image.Image(image, local_feature_extractor=sift_autoencoder) for image in images]\n","\n","\tClusterer.Clusterer.fit_new_trainig(images_pre, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpath_to_save, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnb_clusters=nb_clusters, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_no_improvement=max_no_improvement,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tverbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXvrXUeH0Mq4","colab_type":"code","colab":{}},"source":["def new_pca_components_NN_vlad(images, path_to_save, cluster_centers_path, encoder_model_path, percentage_variance, shape_images, max_key_points):\n","\tautoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n","\tautoencoder.set_model(model_path=encoder_model_path)\n","\tsift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n","\n","\tclusters_centers = Clusterer.Clusterer.fit_ancient_data(cluster_centers_path)\n","\tvlad = Global_feature_exractors.VLAD(clusters_centers)\n","\n","\timages_pre = [Image.Image(path_image, local_feature_extractor=sift_autoencoder, global_feature_extractor=vlad) for path_image in images]\n","\tvlad_vectors = [image.global_descriptor for image in images_pre]\n","\n","\tPCA_reduction.PCA_reduction.plot_variance_nbComponents(vlad_vectors, percentage_variance=percentage_variance)\n","\n","\tPCA_reduction.PCA_reduction.create_new_pca_model(vectors=vlad_vectors, \n","\t                                                 path_to_save=path_to_save, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t percentage_variance=percentage_variance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EiYWmtWq0SuJ","colab_type":"code","colab":{}},"source":["generate_patchs(IMAGES_PATCHS_PATH, \n","                images_train_set,\n","                configuration[\"shape_images\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fsHU7hz0U7V","colab_type":"code","colab":{}},"source":["autoencoder = Autoencoder_train(configuration, IMAGES_PATCHS_PATH, ENCODER_MODEL).train_network()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kY-BVrZJQnSI","colab_type":"code","colab":{}},"source":["choose_number_clusters(images=images_train_set,\n","                        model_path=ENCODER_MODEL,\n","                        max_no_improvement=configuration[\"max_no_improvement\"],\n","                        shape_images=configuration[\"shape_images\"]*2,\n","                        max_key_points=configuration[\"max_key_points\"],\n","                        test_values = range(1, 300, 50))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaQw61kvQr85","colab_type":"code","colab":{}},"source":["nb_clusters_kmeans = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esTQdWge0YDB","colab_type":"code","colab":{}},"source":["save_new_clusters_centers(images_train_set,\n","                          model_path=ENCODER_MODEL,\n","                          path_to_save=CLUSTERS_CENTERS_PATH, \n","                          nb_clusters=nb_clusters_kmeans, \n","                          max_no_improvement=configuration[\"max_no_improvement\"],\n","                          shape_images=configuration[\"shape_images\"]*2,\n","                          max_key_points=configuration[\"max_key_points\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QSBzwUJ0ajN","colab_type":"code","colab":{}},"source":["new_pca_components_NN_vlad(images=images_train_set, \n","                            path_to_save=PCA_MODEL_PATH, \n","                            cluster_centers_path=CLUSTERS_CENTERS_PATH, \n","                            encoder_model_path=ENCODER_MODEL, \n","                            percentage_variance=configuration[\"pca_percentage_variance\"],\n","                            shape_images=configuration[\"shape_images\"]*2,\n","                            max_key_points=configuration[\"max_key_points\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQI10DDt20cK","colab_type":"text"},"source":["#Test Model"]},{"cell_type":"code","metadata":{"id":"VwtVTjX291sy","colab_type":"code","colab":{}},"source":["import importlib, Accuracy\n","importlib.reload(Accuracy)\n","from Accuracy import accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj7KdQnB3jZN","colab_type":"code","colab":{}},"source":["def test_sift_NN_vlad(images, images_names, writers, pca_path, cluster_centers_path, model_path, max_key_points, accuracy_calculator, shape_images):\n","  \n","  autoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n","  autoencoder.set_model(model_path=model_path)\n","  sift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n","\n","  clusters_centers = Clusterer.Clusterer.fit_ancient_data(cluster_centers_path)\n","  pca_instance = PCA_reduction.PCA_reduction(pca_path)\n","  vlad = Global_feature_exractors.VLAD(clusters_centers, pca_instance=pca_instance)\n","\n","  images_pre = [Image.Image(image, image_name=image_name, local_feature_extractor=sift_autoencoder, global_feature_extractor=vlad) for image, image_name in zip(images,images_names)]\n","\n","  cosine_distance = Distances.Distance.cosine_distance\n","  accuracy_value = accuracy_calculator(X_test=images_pre, \n","                                       Y_test=writers, \n","                                       global_feature_extractor=vlad, \n","                                       distance_metric=cosine_distance)\n","  return accuracy_value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ul_KM-UP3VJ8","colab_type":"code","colab":{}},"source":["accuracy_value = test_sift_NN_vlad(images=images_test_set,\n","                                    images_names=images_names_test_set,\n","                                    writers=writers_test_set,\n","                                    pca_path=PCA_MODEL_PATH,\n","                                    cluster_centers_path=CLUSTERS_CENTERS_PATH,\n","                                    model_path=ENCODER_MODEL,\n","                                    max_key_points=configuration[\"max_key_points\"],\n","                                    accuracy_calculator=accuracy,\n","                                    shape_images=configuration[\"shape_images\"]*2)\n","\n","print()\n","print(\"Accuracy value for <\", training_session,\"> : \",\"{:.2%}\".format(accuracy_value), sep=\"\")"],"execution_count":null,"outputs":[]}]}