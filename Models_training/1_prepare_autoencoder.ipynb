{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Clusterer, Global_feature_extractor, Local_features_extractor, Norms, Image, PCA_reduction, Distances, Autoencoder_train, Encoder_NN\n",
    "from Dataset_loader import load_dataset\n",
    "from Accuracy import accuracy_optimised, accuracy\n",
    "import json, os, cv2, pickle\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Encoder_NN)\n",
    "import Autoencoder_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_PATHS = {\n",
    "    \"local_patch_extraction\": [\"SIFT\", \"A-KAZE\"],\n",
    "    \"codebook_generation\": [\"MiniBatchKMeans\", \"KMedoids\"],\n",
    "    \"feature_encoding_and_pooling\": [\"BoVW\", \"VLAD\"],\n",
    "    \"dimentionality_reduction\": [None, \"PCA\"]\n",
    "}\n",
    "DATASETS = [(\"IAM\", None), (\"TrigraphSlant\", False), (\"TrigraphSlant\", True), (\"ICDAR\", \"en\"), (\"ICDAR\", \"ar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = [0, 0, 0, 0]\n",
    "\n",
    "training_session = {\n",
    "    \"id\": \"Akane\",\n",
    "    \"datasets\": [0,1,2,3,4],\n",
    "    \"training_size\": 7,\n",
    "    \"testing_size\": 1\n",
    "}\n",
    "\n",
    "if not os.path.exists(training_session[\"id\"]):\n",
    "  os.mkdir(training_session[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_set, test_big_set = list(), list()\n",
    "\n",
    "for choice in training_session[\"datasets\"]:\n",
    "    train_mini_set, test_mini_set = load_dataset(dataset=DATASETS[choice][0],\n",
    "                                                 path=\"./dataset\", \n",
    "                                                 size_train=training_session[\"training_size\"], \n",
    "                                                 size_test=training_session[\"testing_size\"],\n",
    "                                                 parametre=DATASETS[choice][1])\n",
    "    train_big_set.extend(train_mini_set)\n",
    "    test_big_set.extend(test_mini_set)\n",
    "    \n",
    "_, _, images_train_set = map(list, zip(*train_big_set))\n",
    "writers_test_set, images_names_test_set, images_test_set = map(list, zip(*test_big_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training images:\",len(images_train_set))\n",
    "print(\"Number of testing images:\",len(images_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_configuration = {\n",
    "    \"shape_images\": '?',\n",
    "    \"autoencoder_test_ration\" : 0.3,\n",
    "    \"EPOCHS\" : 25,\n",
    "    \"BS\" :64,\n",
    "    \"latentDim\": '?',\n",
    "    \"max_key_points\" : 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_patch_extraction_methode = PIPELINE_PATHS[\"local_patch_extraction\"][pipline[0]]\n",
    "\n",
    "if local_patch_extraction_methode == \"SIFT\":\n",
    "    local_features_detector = cv2.xfeatures2d.SIFT_create()\n",
    "elif local_patch_extraction_methode == \"A-KAZE\":\n",
    "    local_features_detector = cv2.AKAZE_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_features_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_images = [8, 16, 32]\n",
    "latentDims = [8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patchs(folder, local_features_detector, images, shapes_images, max_samples_by_image):\n",
    "    images_patchs = list()\n",
    "    shapes_images = sorted(shapes_images, reverse=True)\n",
    "    \n",
    "    retained_patches = list()\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        key_points = local_features_detector.detect(image,None)\n",
    "        retained_patches = list()\n",
    "        for key_point in key_points:\n",
    "            retained_mini = []\n",
    "            \n",
    "            y,x = int(key_point.pt[0]),int(key_point.pt[1])\n",
    "            xm, ym = len(image[0]), len(image)\n",
    "            \n",
    "            max_height = shapes_images[0]\n",
    "            cropped = image[x-max_height:x+max_height,y-max_height:y+max_height]\n",
    "            if reduce(lambda x, y: x*y, np.shape(cropped))!=max_height*max_height*4: continue\n",
    "            retained_mini.append(cropped)\n",
    "            \n",
    "            for shape_image in shapes_images[1:]:\n",
    "                cropped = image[x-shape_image:x+shape_image,y-shape_image:y+shape_image]\n",
    "                retained_mini.append(cropped)\n",
    "                \n",
    "            retained_patches.append(retained_mini)\n",
    "                \n",
    "        retained_patches = np.array(retained_patches)\n",
    "        images_patchs.extend(retained_patches[np.random.choice(retained_patches.shape[0], min(max_samples_by_image,len(retained_patches)), replace=False)])\n",
    "        if i!=0 and i%50==0: print(\"50 images treated\")\n",
    "    \n",
    "    print(\"Saving the patchs\")\n",
    "    for i, shape_image in enumerate(shapes_images):\n",
    "        patchs_pickle_path = str(folder)+\"/pickle_patchs_\"+str(shape_image)+\"px.dat\"\n",
    "        with open(patchs_pickle_path, \"wb\") as f:\n",
    "            pickle.dump([row[i] for row in images_patchs], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_patchs(folder=training_session[\"id\"], \n",
    "                local_features_detector=local_features_detector, \n",
    "                images=images_train_set, \n",
    "                shapes_images=shapes_images, \n",
    "                max_samples_by_image=network_configuration[\"max_key_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shape_image in shapes_images:\n",
    "    patchs_pickle_path = training_session[\"id\"]+\"/pickle_patchs_\"+str(shape_image)+\"px.dat\"\n",
    "    with open(patchs_pickle_path,'rb') as f:\n",
    "        data = np.array(pickle.load(f))\n",
    "        print(data.shape)\n",
    "        print(len(data[0]))\n",
    "        print(len(data[0][0]))\n",
    "        print('*'*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values = list()\n",
    "\n",
    "for shape_image in shapes_images:\n",
    "    network_configuration[\"shape_images\"] = shape_image\n",
    "    patchs_pickle_path = training_session[\"id\"]+\"/pickle_patchs_\"+str(shape_image)+\"px.dat\"\n",
    "    for latentDim in latentDims:\n",
    "        network_configuration[\"latentDim\"] = latentDim\n",
    "        model_path = training_session[\"id\"]+\"/Encoder_model_\"+str(shape_image)+\"px_\"+str(latentDim)+\"elem.h5\"\n",
    "        \n",
    "        autoencoder_builder = Autoencoder_train.Autoencoder_train(configuration=network_configuration,\n",
    "                                                            data_path=patchs_pickle_path, \n",
    "                                                            model_path=model_path)\n",
    "        \n",
    "        mse_values.append(autoencoder_builder.train_network())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(local_features_extractor_descriptor, images_train_set, mini_size_sample=12):\n",
    "    images_pre_clustering = [Image.Image(image, local_feature_extractor=local_features_extractor_descriptor) for image in images_train_set]\n",
    "    list_local_descriptors = []\n",
    "    for image in images_pre_clustering:\n",
    "        mini_list_local_descriptors = np.array(image.local_descriptors)\n",
    "        list_local_descriptors.extend(mini_list_local_descriptors[np.random.choice(mini_list_local_descriptors.shape[0], min(mini_size_sample,len(mini_list_local_descriptors)), replace=False)])\n",
    "    return list_local_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_no_improvement = 500\n",
    "clustering_algo = PIPELINE_PATHS[\"codebook_generation\"][pipline[1]]\n",
    "\n",
    "for shape_image in shapes_images:\n",
    "    network_configuration[\"shape_images\"] = shape_image\n",
    "    for latentDim in latentDims:\n",
    "        network_configuration[\"latentDim\"] = latentDim\n",
    "        model_path = training_session[\"id\"]+\"/Encoder_model_\"+str(shape_image)+\"px_\"+str(latentDim)+\"elem.h5\"\n",
    "        \n",
    "        encoder = Encoder_NN.Encoder_NN((network_configuration[\"shape_images\"]*2, network_configuration[\"shape_images\"]*2),\n",
    "                                         network_configuration[\"max_key_points\"], \n",
    "                                         local_features_detector=local_features_detector)\n",
    "        encoder.set_model(model_path=model_path)\n",
    "        local_features_extractor_descriptor = Local_features_extractor.Local_feature_extractor(algorithm=encoder)\n",
    "        descriptors_sample = get_descriptors(local_features_extractor_descriptor, images_train_set)\n",
    "        \n",
    "        Clusterer.Clusterer.choose_number_clusters_clustering(vectors=descriptors_sample, \n",
    "                                                        algo=clustering_algo,\n",
    "                                                        max_no_improvement=max_no_improvement, \n",
    "                                                        test_values=range(2, 300, 50),\n",
    "                                                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}