{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Clusterer, Global_feature_extractor, Local_features_extractor, Norms, Image, PCA_reduction, Distances, Autoencoder_train, Encoder_NN\n",
    "from Dataset_loader import load_dataset\n",
    "from Accuracy import accuracy_optimised, accuracy\n",
    "import json, os, cv2, pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Global_feature_extractor)\n",
    "import Autoencoder_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_PATHS = {\n",
    "    \"local_patch_extraction_representation\":[(\"SIFT\", \"SIFT\"), (\"A-KAZE\", \"A-KAZE\"), (\"SIFT\", \"Autoencoder\"), (\"A-KAZE\", \"Autoencoder\")],\n",
    "    \"codebook_generation\": [\"MiniBatchKMeans\", \"KMedoids\"],\n",
    "    \"feature_encoding_and_pooling\": [\"BoVW\", \"VLAD\"],\n",
    "    \"dimentionality_reduction\": [None, \"PCA\"]\n",
    "}\n",
    "DATASETS = [(\"IAM\", None), (\"TrigraphSlant\", False), (\"TrigraphSlant\", True), (\"ICDAR\", \"en\"), (\"ICDAR\", \"ar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = [0, 0, 1, 1]\n",
    "\n",
    "training_session = {\n",
    "    \"id\": \"Tanya\",\n",
    "    \"datasets\": [1,2],\n",
    "    \"training_size\": 10,\n",
    "    \"testing_size\": 1\n",
    "}\n",
    "\n",
    "if not os.path.exists(training_session[\"id\"]):\n",
    "  os.mkdir(training_session[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_set, test_big_set = list(), list()\n",
    "\n",
    "for choice in training_session[\"datasets\"]:\n",
    "    train_mini_set, test_mini_set = load_dataset(dataset=DATASETS[choice][0],\n",
    "                                                 path=\"./dataset\", \n",
    "                                                 size_train=training_session[\"training_size\"], \n",
    "                                                 size_test=training_session[\"testing_size\"],\n",
    "                                                 parametre=DATASETS[choice][1])\n",
    "    train_big_set.extend(train_mini_set)\n",
    "    test_big_set.extend(test_mini_set)\n",
    "    \n",
    "_, _, images_train_set = map(list, zip(*train_big_set))\n",
    "writers_test_set, images_names_test_set, images_test_set = map(list, zip(*test_big_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training images:\",len(images_train_set))\n",
    "print(\"Number of testing images:\",len(images_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_chosen = PIPELINE_PATHS[\"local_patch_extraction_representation\"][pipline[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modules_chosen == (\"SIFT\", \"SIFT\"):\n",
    "  hellinger_normalization = Norms.Norm.hellinger_normalization\n",
    "  algo = cv2.xfeatures2d.SIFT_create()\n",
    "  local_features_extractor_descriptor = Local_features_extractor.Local_feature_extractor(algorithm=algo, norm=hellinger_normalization)\n",
    "elif modules_chosen == (\"A-KAZE\", \"A-KAZE\"):\n",
    "  hellinger_normalization = Norms.Norm.hellinger_normalization\n",
    "  algo = cv2.AKAZE_create()\n",
    "  local_features_extractor_descriptor = Local_features_extractor.Local_feature_extractor(algorithm=algo, norm=hellinger_normalization)\n",
    "else:\n",
    "    shape_images = '?'\n",
    "    max_key_points = '?'\n",
    "    model_path = '?'\n",
    "    if modules_chosen[0] == \"SIFT\":\n",
    "      local_features_detector = cv2.xfeatures2d.SIFT_create()\n",
    "    elif modules_chosen[0] == \"A-KAZE\":\n",
    "      local_features_detector = cv2.AKAZE_create()\n",
    "    encoder = Encoder_NN.Encoder_NN((network_configuration[shape_images]*2, network_configuration[shape_images]*2),\n",
    "                                     network_configuration[max_key_points], \n",
    "                                     local_features_detector=local_features_detector)\n",
    "    encoder.set_model(model_path=model_path)\n",
    "    local_features_extractor_descriptor = Local_features_extractor.Local_feature_extractor(algorithm=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(local_features_extractor_descriptor, images_train_set, mini_size_sample=12):\n",
    "    images_pre_clustering = [Image.Image(image, local_feature_extractor=local_features_extractor_descriptor) for image in images_train_set]\n",
    "    list_local_descriptors = []\n",
    "    list_local_descriptors_all = []\n",
    "    for image in images_pre_clustering:\n",
    "        mini_list_local_descriptors = np.array(image.local_descriptors)\n",
    "        list_local_descriptors_all.extend(mini_list_local_descriptors[np.random.choice(mini_list_local_descriptors.shape[0], len(mini_list_local_descriptors), replace=False)])\n",
    "        list_local_descriptors.extend(mini_list_local_descriptors[np.random.choice(mini_list_local_descriptors.shape[0], min(mini_size_sample,len(mini_list_local_descriptors)), replace=False)])\n",
    "    return list_local_descriptors_all, list_local_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_all, descriptors_sample = get_descriptors(local_features_extractor_descriptor, images_train_set)\n",
    "print(len(descriptors_sample))\n",
    "print(len(descriptors_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_algo = PIPELINE_PATHS[\"codebook_generation\"][pipline[1]]\n",
    "max_no_improvement = 500\n",
    "test_values=range(2, 100, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterer.Clusterer.choose_number_clusters_clustering(vectors=descriptors_sample, \n",
    "                                                      algo=clustering_algo,\n",
    "                                                      max_no_improvement=max_no_improvement, \n",
    "                                                      test_values=test_values,\n",
    "                                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = 50\n",
    "clusters_centers_path = training_session[\"id\"]+\"/Centers_clusters_\"+str(nb_clusters)+\"nb.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterer.Clusterer.fit_new_trainig(vectors=descriptors_all,\n",
    "                                    algo= clustering_algo,\n",
    "                                    path_to_save=clusters_centers_path,\n",
    "                                    nb_clusters=nb_clusters, \n",
    "                                    max_no_improvement=max_no_improvement,\n",
    "                                    metric=None,\n",
    "                                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_chosen = PIPELINE_PATHS[\"feature_encoding_and_pooling\"][pipline[2]]\n",
    "if module_chosen == \"BoVW\":\n",
    "  global_feature_extractor = Global_feature_extractor.BOW(clusters_centers_path=clusters_centers_path)\n",
    "elif module_chosen == \"VLAD\":\n",
    "  global_feature_extractor = Global_feature_extractor.VLAD(clusters_centers_path=clusters_centers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_variance = 0.98\n",
    "pca_model_path = training_session[\"id\"]+\"/pca_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (PIPELINE_PATHS[\"dimentionality_reduction\"][pipline[3]] == \"PCA\") and (module_chosen == \"VLAD\"):\n",
    "    images_pre = [Image.Image(image, local_feature_extractor=local_features_extractor_descriptor, global_feature_extractor=global_feature_extractor) for image in images_train_set]\n",
    "    global_descriptors = [image.global_descriptor for image in images_pre]\n",
    "    PCA_reduction.PCA_reduction.plot_variance_nbComponents(global_descriptors, percentage_variance=percentage_variance)\n",
    "    PCA_reduction.PCA_reduction.create_new_pca_model(vectors=global_descriptors, \n",
    "                                                    path_to_save=pca_model_path, \n",
    "                                                    percentage_variance=percentage_variance)\n",
    "\n",
    "    pca_instance = PCA_reduction.PCA_reduction(pca_model_path)\n",
    "    global_feature_extractor = Global_feature_extractor.VLAD(clusters_centers_path=clusters_centers_path, pca_instance=pca_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_patch_representation = PIPELINE_PATHS[\"local_patch_extraction_representation\"][pipline[0]][1]\n",
    "if local_patch_representation==\"Autoencoder\":\n",
    "  distance_metric = Distances.Distance.angular_distance\n",
    "  accuracy_calculator = accuracy\n",
    "else:\n",
    "  distance_metric = Distances.Distance.chi2_distance\n",
    "  accuracy_calculator = accuracy_optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_pre = [Image.Image(image, image_name=image_name, local_feature_extractor=local_features_extractor_descriptor, global_feature_extractor=global_feature_extractor) for image, image_name in zip(images_test_set,images_names_test_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_value = accuracy_calculator(X_test=images_pre, \n",
    "                                     Y_test=writers_test_set,\n",
    "                                     distance_metric=distance_metric)\n",
    "\n",
    "print(\"*\"*24)\n",
    "print(\"Accuracy value for <\", training_session,\"> : \",\"{:.2%}\".format(accuracy_value), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
