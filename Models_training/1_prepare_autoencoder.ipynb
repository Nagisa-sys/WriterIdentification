{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages Importation and parameters specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Clusterer, Global_feature_extractor, Local_features_extractor, Norms, Image, PCA_reduction\n",
    "import Distances, Autoencoder_train, Encoder_NN\n",
    "from Dataset_loader import load_dataset\n",
    "from Accuracy import accuracy_optimised, accuracy\n",
    "import json, os, cv2, pickle\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_PATHS = {\n",
    "    \"local_patch_extraction\": [\"SIFT\", \"A-KAZE\"],\n",
    "    \"codebook_generation\": [\"MiniBatchKMeans\", \"KMedoids\"],\n",
    "    \"feature_encoding_and_pooling\": [\"BoVW\", \"VLAD\"],\n",
    "    \"dimentionality_reduction\": [None, \"PCA\"]\n",
    "}\n",
    "DATASETS = [(\"IAM\", None), (\"TrigraphSlant\", False), (\"TrigraphSlant\", True), (\"ICDAR\", \"en\"), (\"ICDAR\", \"ar\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline = [0, 0, 0, 0]\n",
    "\n",
    "training_session = {\n",
    "    \"id\": \"Akane\",\n",
    "    \"datasets\": [0,1,2,3,4],\n",
    "    \"training_size\": 7,\n",
    "    \"testing_size\": 1\n",
    "}\n",
    "\n",
    "if not os.path.exists(training_session[\"id\"]):\n",
    "  os.mkdir(training_session[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_configuration = {\n",
    "    \"shape_images\": '?',\n",
    "    \"autoencoder_test_ration\" : 0.3,\n",
    "    \"EPOCHS\" : 25,\n",
    "    \"BS\" :64,\n",
    "    \"latentDim\": '?',\n",
    "    \"max_key_points\" : 250\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_set, test_big_set = list(), list()\n",
    "\n",
    "for choice in training_session[\"datasets\"]:\n",
    "    train_mini_set, test_mini_set = load_dataset(dataset=DATASETS[choice][0],\n",
    "                                                 path=\"./dataset\", \n",
    "                                                 size_train=training_session[\"training_size\"], \n",
    "                                                 size_test=training_session[\"testing_size\"],\n",
    "                                                 parametre=DATASETS[choice][1])\n",
    "    train_big_set.extend(train_mini_set)\n",
    "    test_big_set.extend(test_mini_set)\n",
    "    \n",
    "_, _, images_train_set = map(list, zip(*train_big_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training images:\",len(images_train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patchs extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_images = [8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_patch_extraction_methode = PIPELINE_PATHS[\"local_patch_extraction\"][pipline[0]]\n",
    "\n",
    "if local_patch_extraction_methode == \"SIFT\":\n",
    "    local_features_detector = cv2.xfeatures2d.SIFT_create()\n",
    "elif local_patch_extraction_methode == \"A-KAZE\":\n",
    "    local_features_detector = cv2.AKAZE_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patchs(folder, local_features_detector, images, shapes_images, max_samples_by_image):\n",
    "    images_patchs = list()\n",
    "    shapes_images = sorted(shapes_images, reverse=True)\n",
    "    \n",
    "    retained_patches = list()\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        key_points = local_features_detector.detect(image,None)\n",
    "        retained_patches = list()\n",
    "        for key_point in key_points:\n",
    "            retained_mini = []\n",
    "            \n",
    "            y,x = int(key_point.pt[0]),int(key_point.pt[1])\n",
    "            xm, ym = len(image[0]), len(image)\n",
    "            \n",
    "            max_height = shapes_images[0]\n",
    "            cropped = image[x-max_height:x+max_height,y-max_height:y+max_height]\n",
    "            if reduce(lambda x, y: x*y, np.shape(cropped))!=max_height*max_height*4: continue\n",
    "            retained_mini.append(cropped)\n",
    "            \n",
    "            for shape_image in shapes_images[1:]:\n",
    "                cropped = image[x-shape_image:x+shape_image,y-shape_image:y+shape_image]\n",
    "                retained_mini.append(cropped)\n",
    "                \n",
    "            retained_patches.append(retained_mini)\n",
    "                \n",
    "        retained_patches = np.array(retained_patches)\n",
    "        images_patchs.extend(retained_patches[\n",
    "            np.random.choice(retained_patches.shape[0], \n",
    "                             min(max_samples_by_image,len(retained_patches)), \n",
    "                             replace=False)\n",
    "        ])\n",
    "        if i!=0 and i%50==0: print(\"50 images treated\")\n",
    "    \n",
    "    print(\"Saving the patchs\")\n",
    "    for i, shape_image in enumerate(shapes_images):\n",
    "        patchs_pickle_path = str(folder)+\"/pickle_patchs_\"+str(shape_image)+\"px.dat\"\n",
    "        with open(patchs_pickle_path, \"wb\") as f:\n",
    "            pickle.dump([row[i] for row in images_patchs], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_patchs(folder=training_session[\"id\"], \n",
    "                local_features_detector=local_features_detector, \n",
    "                images=images_train_set, \n",
    "                shapes_images=shapes_images, \n",
    "                max_samples_by_image=network_configuration[\"max_key_points\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal latent dimention for each patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latentDims = [8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values = list()\n",
    "\n",
    "for shape_image in shapes_images:\n",
    "    network_configuration[\"shape_images\"] = shape_image\n",
    "    patchs_pickle_path = training_session[\"id\"]+\"/pickle_patchs_\"+str(shape_image)+\"px.dat\"\n",
    "    for latentDim in latentDims:\n",
    "        network_configuration[\"latentDim\"] = latentDim\n",
    "        model_path = training_session[\"id\"]+\"/Encoder_model_\"+str(shape_image)+\"px_\"+str(latentDim)+\"elem.h5\"\n",
    "        \n",
    "        autoencoder_builder = Autoencoder_train.Autoencoder_train(configuration=network_configuration,\n",
    "                                                            data_path=patchs_pickle_path, \n",
    "                                                            model_path=model_path)\n",
    "        \n",
    "        mse_values.append(autoencoder_builder.train_network())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
