{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSBXRqGMmLVu"
   },
   "source": [
    "# Modules Importation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buSqBXaSuzzQ"
   },
   "outputs": [],
   "source": [
    "WORK_DIR = \".\"\n",
    "%cd \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdLCQ9Bt2dQr"
   },
   "outputs": [],
   "source": [
    "import Clusterer, Global_feature_exractors, Local_features_extractor, Norms, Image, PCA_reduction, Distances, Autoencoder\n",
    "from Dataset_loader import load_dataset\n",
    "from Accuracy import accuracy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEJQU9UC2t2y"
   },
   "outputs": [],
   "source": [
    "training_session = \"training_16Sep\"\n",
    "\n",
    "with open(\"./config_train.json\") as config_file:\n",
    "  configuration = json.load(config_file)[\"Sift_Encoder_Vlad_Pca\"][training_session]\n",
    "\n",
    "dataset = configuration[\"dataset\"]\n",
    "dataset_path = configuration[\"dataset_path\"]\n",
    "CLUSTERS_CENTERS_PATH = training_session+\"/NN_\"+dataset+\"_centers_clusters.npy\"\n",
    "PCA_MODEL_PATH = training_session+\"/NN_\"+dataset+\"_pca_model.pkl\"\n",
    "IMAGES_PATCHS_PATH = training_session+\"/NN_\"+dataset+\"_pickle_patchs.dat\"\n",
    "ENCODER_MODEL = training_session+\"/NN_\"+dataset+\"_Encoder_model.h5\"\n",
    "\n",
    "if not os.path.exists(training_session):\n",
    "  os.mkdir(training_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkUoXwRyCVyP"
   },
   "outputs": [],
   "source": [
    "train, test = load_dataset(dataset, dataset_path, size_train=configuration[\"train_size\"], size_test=configuration[\"test_size\"])\n",
    "_, _, images_train_set = map(list, zip(*train))\n",
    "writers_test_set, images_names_test_set, images_test_set = map(list, zip(*test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3dPV7mpq0OC"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPKe6E3NuaFB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLkiVQa975zH"
   },
   "outputs": [],
   "source": [
    "class Autoencoder_train:\n",
    "\tdef __init__(self, configuration, data_path, model_path):\n",
    "\t\tself.configuration = configuration\n",
    "\t\tself.shape_images = (configuration[\"shape_images\"]*2,configuration[\"shape_images\"]*2)\n",
    "\t\tself.model_path = model_path\n",
    "\t\tself.data_path = data_path\n",
    "\n",
    "\tdef train_network(self):\n",
    "\t\ttest_ration = self.configuration[\"autoencoder_test_ration\"]\n",
    "\t\tEPOCHS = self.configuration[\"EPOCHS\"]\n",
    "\t\tBS = self.configuration[\"BS\"]\n",
    "\n",
    "\t\ttrainX, testX = self.load_data_patchs(self.data_path, test_ration)\n",
    "\n",
    "\t# add a channel dimension to every image in the dataset, then scale\n",
    "\t# the pixel intensities to the range [0, 1]\n",
    "\t\ttrainX \t= np.expand_dims(trainX, axis=-1)\n",
    "\t\ttestX \t= np.expand_dims(testX, axis=-1)\n",
    "\t\ttrainX \t= trainX.astype(\"float32\") / 255.0\n",
    "\t\ttestX \t= testX.astype(\"float32\") / 255.0\n",
    "\n",
    "\t# construct the convolutional autoencoder\n",
    "\t\tprint(\"[INFO] building autoencoder...\")\n",
    "\t\t(encoder, decoder, autoencoder) = self.build(self.shape_images[0], self.shape_images[1], 1)\n",
    "\t\tautoencoder.compile(loss=\"mse\", optimizer=Adam(lr=1e-3))\n",
    "\n",
    "\t# train the convolutional autoencoder\n",
    "\t\tH = autoencoder.fit(trainX, trainX,\n",
    "\t\t\t\t\t\t\tvalidation_data=(testX, testX),\n",
    "\t\t\t\t\t\t\tepochs=EPOCHS,\n",
    "\t\t\t\t\t\t\tbatch_size=BS)\n",
    "\n",
    "\t\tself.plot_loss_accuracy(H, EPOCHS)\n",
    "\t\tencoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(\"encoder\").output)\n",
    "\t\tself.save_model(encoder, self.model_path)\n",
    "\t\tself.test_autoencoder(autoencoder, testX)\n",
    "\t\n",
    "\tdef test_autoencoder(self, autoencoder, testX):\n",
    "\t\tprint(\"[INFO] making predictions...\")\n",
    "\t\tdecoded = autoencoder.predict(testX)\n",
    "\t\toutputs = None\n",
    "\t\tfor i in range(0, 20):\n",
    "\t\t\toriginal = (testX[i] * 255).astype(\"uint8\")\n",
    "\t\t\trecon = (decoded[i] * 255).astype(\"uint8\")\n",
    "\t\t\toutput = np.hstack([original, recon])\n",
    "\t\t\tif outputs is None:\n",
    "\t\t\t\toutputs = output\n",
    "\t\t\telse:\n",
    "\t\t\t\toutputs = np.vstack([outputs, output])\n",
    "\t\tcv2_imshow(outputs)\n",
    "\n",
    "\tdef load_data_patchs(self, PIK, test_ration):\n",
    "\t\twith open(PIK,'rb') as f:\n",
    "\t\t\tdata = np.array(pickle.load(f))\n",
    "\n",
    "\t\tsize_test = int(len(data)*test_ration)\n",
    "\t\tnp.random.shuffle(data)\n",
    "\t\treturn data[size_test:], data[:size_test]\n",
    "\n",
    "\n",
    "\tdef save_model(self, model, model_path):\n",
    "\t\tsave_format = \"h5\"\n",
    "\t\tprint(\"[INFO] saving encoder...\")\n",
    "\t\tmodel.save(model_path, save_format=save_format, include_optimizer=False)\n",
    "\n",
    "\n",
    "\tdef plot_loss_accuracy(self, H, EPOCHS):\n",
    "\t\tN = np.arange(0, EPOCHS)\n",
    "\t\tplt.style.use(\"ggplot\")\n",
    "\t\tplt.figure()\n",
    "\t\tplt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "\t\tplt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\t\tplt.title(\"Training Loss and Accuracy\")\n",
    "\t\tplt.xlabel(\"Epoch #\")\n",
    "\t\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\t\tplt.legend(loc=\"lower left\")\n",
    "\n",
    "\n",
    "\t\n",
    "\tdef build(self, width, height, depth, filters=(32, 64)):\n",
    "\t\tlatentDim = self.configuration[\"latentDim\"]\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\n",
    "\t\tinputs = Input(shape=inputShape)\n",
    "\t\tx = inputs\n",
    "\n",
    "\t\tfor f in filters:\n",
    "\t\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\n",
    "\t\tvolumeSize = K.int_shape(x)\n",
    "\t\tx = Flatten()(x)\n",
    "\t\tlatent = Dense(latentDim)(x)\n",
    "\t\tencoder = Model(inputs, latent, name=\"encoder\")\n",
    "\n",
    "\t\tprint(encoder.summary())\n",
    "\n",
    "\t\tlatentInputs = Input(shape=(latentDim,))\n",
    "\t\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
    "\t\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
    "\n",
    "\t\tfor f in filters[::-1]:\n",
    "\t\t\tx = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\n",
    "\t\tx = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
    "\t\toutputs = Activation(\"sigmoid\")(x)\n",
    "\t\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n",
    "\n",
    "\t\tautoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n",
    "\t\treturn (encoder, decoder, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29t55ZW5zfPJ"
   },
   "outputs": [],
   "source": [
    "def generate_patchs(PatchsPickle, images, height):\n",
    "\tsift = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm)\n",
    "\timages_pre = [Image.Image(image, local_feature_extractor=sift) for image in images]\n",
    "\timages_patch = list()\n",
    "\n",
    "\tfor image in images_pre:\n",
    "\t\tfor key_point in image.key_points:\n",
    "\t\t\ty,x = int(key_point.pt[0]),int(key_point.pt[1])\n",
    "\t\t\txm, ym = image.image.shape\n",
    "\t\t\tif (x-height < 0) or (x+height > xm) or (y-height < 0) or (y+height > ym):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcropped = image.image[x-height:x+height,y-height:y+height]\n",
    "\t\t\timages_patch.append(cropped)\n",
    "\n",
    "\twith open(PatchsPickle, \"wb\") as f:\n",
    "\t\tpickle.dump(images_patch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiYWmtWq0SuJ"
   },
   "outputs": [],
   "source": [
    "generate_patchs(IMAGES_PATCHS_PATH, \n",
    "                images_train_set,\n",
    "                configuration[\"shape_images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fsHU7hz0U7V"
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder_train(configuration, IMAGES_PATCHS_PATH, ENCODER_MODEL).train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_list_descriptors_to_cluster(images, model_path, max_no_improvement, shape_images, max_key_points):\n",
    "    autoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n",
    "\tautoencoder.set_model(model_path=model_path)\n",
    "\tsift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n",
    "\n",
    "\timages_pre = [Image.Image(image, local_feature_extractor=sift_autoencoder) for image in images]\n",
    "  \n",
    "    descriptor_list = []\n",
    "    [descriptor_list.extend(image.local_descriptors) for image in images_pre]\n",
    "    \n",
    "    return descriptor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_local_descriptors = prepare_list_descriptors_to_cluster(images=images_train_set,\n",
    "                                            model_path=ENCODER_MODEL,\n",
    "                                            max_no_improvement=configuration[\"max_no_improvement\"],\n",
    "                                            shape_images=configuration[\"shape_images\"]*2,\n",
    "                                            max_key_points=configuration[\"max_key_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterer.Clusterer.elbow_method_kmeans(vectors=list_local_descriptors, \n",
    "                                     max_no_improvement=configuration[\"max_no_improvement\"], \n",
    "                                     test_values=range(1, 401, 50),\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters_kmeans = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterer.Clusterer.fit_new_trainig(list_local_descriptors, \n",
    "                                     path_to_save=CLUSTERS_CENTERS_PATH, \n",
    "                                     nb_clusters=nb_clusters_kmeans, \n",
    "                                     max_no_improvement=configuration[\"max_no_improvement\"],\n",
    "                                     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXvrXUeH0Mq4"
   },
   "outputs": [],
   "source": [
    "def new_pca_components_NN_vlad(images, path_to_save, cluster_centers_path, encoder_model_path, percentage_variance, shape_images, max_key_points):\n",
    "\tautoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n",
    "\tautoencoder.set_model(model_path=encoder_model_path)\n",
    "\tsift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n",
    "\n",
    "\tclusters_centers = Clusterer.Clusterer.fit_ancient_data(cluster_centers_path)\n",
    "\tvlad = Global_feature_exractors.VLAD(clusters_centers)\n",
    "\n",
    "\timages_pre = [Image.Image(path_image, local_feature_extractor=sift_autoencoder, global_feature_extractor=vlad) for path_image in images]\n",
    "\tvlad_vectors = [image.global_descriptor for image in images_pre]\n",
    "\n",
    "\tPCA_reduction.PCA_reduction.plot_variance_nbComponents(vlad_vectors, percentage_variance=percentage_variance)\n",
    "\n",
    "\tPCA_reduction.PCA_reduction.create_new_pca_model(vectors=vlad_vectors, \n",
    "\t                                                 path_to_save=path_to_save, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t percentage_variance=percentage_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QSBzwUJ0ajN"
   },
   "outputs": [],
   "source": [
    "new_pca_components_NN_vlad(images=images_train_set, \n",
    "                            path_to_save=PCA_MODEL_PATH, \n",
    "                            cluster_centers_path=CLUSTERS_CENTERS_PATH, \n",
    "                            encoder_model_path=ENCODER_MODEL, \n",
    "                            percentage_variance=configuration[\"pca_percentage_variance\"],\n",
    "                            shape_images=configuration[\"shape_images\"]*2,\n",
    "                            max_key_points=configuration[\"max_key_points\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQI10DDt20cK"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwtVTjX291sy"
   },
   "outputs": [],
   "source": [
    "import importlib, Accuracy\n",
    "importlib.reload(Accuracy)\n",
    "from Accuracy import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj7KdQnB3jZN"
   },
   "outputs": [],
   "source": [
    "def test_sift_NN_vlad(images, images_names, writers, pca_path, cluster_centers_path, model_path, max_key_points, accuracy_calculator, shape_images):\n",
    "  \n",
    "  autoencoder = Autoencoder.Encoder_NN((shape_images, shape_images), max_key_points)\n",
    "  autoencoder.set_model(model_path=model_path)\n",
    "  sift_autoencoder = Local_features_extractor.Local_feature_exractor(Norms.Norm.No_norm, local_feature_extractor=autoencoder)\n",
    "\n",
    "  clusters_centers = Clusterer.Clusterer.fit_ancient_data(cluster_centers_path)\n",
    "  pca_instance = PCA_reduction.PCA_reduction(pca_path)\n",
    "  vlad = Global_feature_exractors.VLAD(clusters_centers, pca_instance=pca_instance)\n",
    "\n",
    "  images_pre = [Image.Image(image, image_name=image_name, local_feature_extractor=sift_autoencoder, global_feature_extractor=vlad) for image, image_name in zip(images,images_names)]\n",
    "\n",
    "  cosine_distance = Distances.Distance.cosine_distance\n",
    "  accuracy_value = accuracy_calculator(X_test=images_pre, \n",
    "                                       Y_test=writers, \n",
    "                                       global_feature_extractor=vlad, \n",
    "                                       distance_metric=cosine_distance)\n",
    "  return accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ul_KM-UP3VJ8"
   },
   "outputs": [],
   "source": [
    "accuracy_value = test_sift_NN_vlad(images=images_test_set,\n",
    "                                    images_names=images_names_test_set,\n",
    "                                    writers=writers_test_set,\n",
    "                                    pca_path=PCA_MODEL_PATH,\n",
    "                                    cluster_centers_path=CLUSTERS_CENTERS_PATH,\n",
    "                                    model_path=ENCODER_MODEL,\n",
    "                                    max_key_points=configuration[\"max_key_points\"],\n",
    "                                    accuracy_calculator=accuracy,\n",
    "                                    shape_images=configuration[\"shape_images\"]*2)\n",
    "\n",
    "print()\n",
    "print(\"Accuracy value for <\", training_session,\"> : \",\"{:.2%}\".format(accuracy_value), sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0ZhVIMFegPmS+jzLU/f5W",
   "collapsed_sections": [],
   "name": "Training_Sift_Encoder_Vlad_Pca.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}